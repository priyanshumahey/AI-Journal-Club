{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1: Introduction to Machine Learning, Perceptrons and PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start off discussing anyting too complex, let's first take a look at what machine learning truly is. Machine learning is a branch of artifical intelligence that focuses on utilizing data and algorithms to mimic human neural interactions. The goal of machine learning is to mimic how humans solve task through the use of neural networks which are essentially computer simulations of real life neurons and nervous systems. \n",
    "\n",
    "In machine learning, we have supervised and unsupervised learning. **Supervised learning** is the use of labeled datasets to train neural algorithms. Supervised learning learns to map inputs x to outputs y given a labeled set of input-output pairs $D = \\{ (x_i, y_i ) \\}^{N}_{i=1}$ where $D$ represents the training set and $ N $ represents the number of training examples. **Unsupervised learning** is when we're given inputs $ D = \\{x_{i}\\}^{N}_{i=1} $. We aren't given any set outputs and here our goal is to discover and explore relationships and interesting patterns within the data. We also have another type of machine learning called reinforcement learning which is more complex than our current scope. For now, we'll be focusing on supervised and unsupervised."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go too deep into deep neural networks, we'll be starting off with simple shallow neural networks and some basic machine learning related tasks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear and Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned prior, regression problems appear when we want to predict a numerical value. Linear regression is the simplest and most popular standard tools for regression problems. Linear regression assumes that the relationship between the input and output is approximately linear. This means that the ouput y can be mapped with the input x as $y=wx + b$ where $w$ represents the weights and $b$ represents the bias."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start off by initializing a weight vector and then finding the best weight vector to model the model through least squares method or gradient descent learning. \n",
    "\n",
    "**Mean squared error** is an error metric (allows us to keep track of accuracy and erorr of the our test). MSE is a risk function that determines the average squared difference between the predicted and actual value of a feature or variable. The formula for MSE is as follows:\n",
    "\n",
    "$$ MSE = \\frac{1}{n}\\sum{(Predicted-Actual)^2} $$\n",
    "\n",
    "Here we sum up all the squares of predicted - actual and then divide it by the number of trials/pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = [1,2,3,4,5]\n",
    "predicted = [1.1,2.3,3.1,4.2,5.1]\n",
    "\n",
    "MSE = np.square(np.subtract(predicted, actual)).mean()\n",
    "\n",
    "print(MSE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, our objective is to reduce the error between the predicted and actual data. We want to minimize the error and improve the overall preformance of the machine learning model. \n",
    "\n",
    "In order to figure out which weights and parameters work best for the linear regression model, we'll be using an algorithm to find out the optimal set of parameters that allow us to minimize the loss function. **Gradient descent** is the most popular optimization algorithm in machine learning. Gradient descent iteratively calculates the gradients of the loss function and continuously updates the parameters until we reach the local minima. We'll touch upon the gradient descent algorithm again a bit later as it's a very crucial algorithm in machine learning.\n",
    "\n",
    "To implement gradient descent, we follow the following steps:\n",
    "\n",
    "1. Initialize parameters\n",
    "2. Calculate partial derivative with respect to parameters\n",
    "3. Update parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    def __init__(self, learning_rate, iterations):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "    \n",
    "    def model_training(self, x, y):\n",
    "        self.training_examples, self.number_of_features = x.shape\n",
    "        self.w = np.zeros( self.number_of_features )\n",
    "        self.b = 0\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "        for i in range(self.iterations):\n",
    "            self.update_weights()\n",
    "        \n",
    "        return self \n",
    "    \n",
    "    def update_weights(self):\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrons\n",
    "\n",
    "Let's start off by discussing a very basic neural network unit! Perceptrons are very basic neural network units that can. The perceptron is an important step in understanding deep learning and we'll start off by discussing the different parts of it and when perceptrons are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch\n",
    "\n",
    "\n",
    "https://pytorch.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrons in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today's Paper\n",
    "\n",
    "Today we will be discussing a very old paper on perceptrons: https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.335.3398&rep=rep1&type=pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "156b6e445808b07dc40aa5a8e66ccf91c9fbe531dfe1445bc12a4896e0fba728"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
