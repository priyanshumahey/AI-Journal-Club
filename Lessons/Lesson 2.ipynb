{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2: Machine Learning Basics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, one of the major goals is to uncover patterns hidden inside large datasets. But when doing this, it is important to ensure the pattern is generalizable which means that it applies to data beyond the dataset we've given to the algorithm for training.\n",
    "When we make AI, we want it to be able to generalize and figure out larger overall patterns. When using machine learning algorithms, it is highly important to make sure that the algorithm is able to discover a generalizable pattern.\n",
    "\n",
    "The phenomenon of fitting closer to our training data than to the underlying distribution is called _overfitting_, and techniques for combatting overfitting are called _regularization_ methods."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Error and Generalization Error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, for supervised learning settings, we assume the training data and the test data are drawn independently from identical distributions (IID assumption). Without this assumption, our models do not work. If this assumption isn't true, why would we beleive that one training distribution can tell us about another training distribution? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training error** $R_{emp}$ is a statistic calculated on the training dataset. **Generalization error** $R$, which is an expectation taken with respect to the underlying distribution. Generalization error can be thought of as what you would see if you applied your model to an infinite stream of additional data examples drawn from the same underlying data distribution. Formally, we can express training error as a sum:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "R_{emp}[X,y,f] = \\frac{1}{n} \\sum_{i=1}^{n}l(x^{(i)}, y^{(i)}, f(x^{(i)}))\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generalization error can be expressed as a sum:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "R[p,f] = E_{(x,y)~P}[l(x,y,f(x))] = \\int \\space \\int l(x, y, f(x))p(x,y)dx dy\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can never truly calculate the generalization error exactly since we don't know the percise form of the density function and we cannot sample an infinite stream of datapoints. Thus, we estimate the generalization error by applying our model to an independent test set of randomly selected examples $X'$ and labels $y'$ that were withheld from our training set. This consists of applying the same formula as for calculating the empirical training error but to a test set $X'y'$. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Complexity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have simple models and abundant data, the training and generalization errors tend to be close. When we work with more complex models and/or fewer examples, we expect the training error to go down but the generalization gap continues to grow. \n",
    "\n",
    "Note that low training error does not necessariily imply low generalization error. To get a proper sense of the true error, we use a validation set and recieve a validation error."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to training and validation erros, we need to be careful of two scenarios:\n",
    "\n",
    "- First is what happens bwhen our training error and validation error are both substantial but little gap between them. If the model is unable to reduce the training error, it could mean the model isn't expressive enough to capture the pattern (ie it's too simple). Since the generalization gap ($R_{emp} - R$) is small, we could use a more complex model. This is called **underfitting**.\n",
    "\n",
    "- If our training error is significantly lower than our validation error, this indicates our model is **overfitting**. This is due to the model recognizing too strong of a pattern on the training data and the training data only leading it to be poorly generalizable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Free Lunch Theorem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **no free lunch theorem** suggests that on averaging over on all possible data generating distributions, every classification has the same error rate when classifying previously unobserved points which means that no machine learning algorithm is universally better than others. This theorem suggests that the performance of all optimization algorithms are identical under some constraints. This theorem suggests we must design our machine learning algorithms to perform well on specific tasks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization is an important part of tuning a model and helps to reduce overfitting. There are a couple of different regularization techniques which include familiar terms such as l1 and regularization.\n",
    "\n",
    "- **L1 regularization**: adds L1 penalty that is equal to the absolute value of the magnitude of the coefficient or simply restricting size of coefficients (eg Lasso regression)\n",
    "- **L2 Regularization**: adds L2 penalty that is equal to the square of the magnitude of coefficients (eg Ridge regression, SVM)\n",
    "- **Elastic Net**: L1 and L2 regularization combined together adding a hyperparamter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1 Regularization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 regularization makes some coefficients zero meaning the model will ignore those features and this helps to emphasize the model's essential features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "L1 = Loss \\space function + \\lambda \\sum_{j=1}^{m} |w_j|\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here $\\lambda$ controls the strength of regularization and $w_j$ represents the model's weights (coefficients)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Decay"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weight decay** is a regularization technique. It works by restricting the values that the paramters can take."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
